import re
from spacy.lang.pt.stop_words import STOP_WORDS 
from huggingface_hub import hf_hub_download
from safetensors.numpy import load_file
from gensim.models import KeyedVectors

print("üìö Iniciando carregamento inteligente (Smart Load)...")

# Filtra palavras in√∫teis do vocabul√°rio
def palavra_eh_valida(palavra):
    """Retorna True se a palavra for √∫til para o jogo."""
    
    # Tamanho m√≠nimo
    if len(palavra) < 2: return False

    # Sem espa√ßos ou underscores
    if ' ' in palavra or '_' in palavra: return False
    
    # Preposi√ß√µes e artigos comuns
    if palavra in STOP_WORDS: return False

    # Caracteres inv√°lidos (apenas letras min√∫sculas e acentuadas)
    if re.search(r'[^a-z√°√°√†√¢√£√©√®√™√≠√Ø√≥√¥√µ√∂√∫√ß√±]', palavra): return False
    
    return True

# Carregamento e processamento
word2vec = None

try:
    # Verifica se os arquivos do modelo est√£o no cache ou faz o download
    emb_path = hf_hub_download(repo_id="nilc-nlp/fasttext-skip-gram-300d", filename="embeddings.safetensors")
    vocab_path = hf_hub_download(repo_id="nilc-nlp/fasttext-skip-gram-300d", filename="vocab.txt")

    indices_validos = []
    palavras_validas = []
    
    # Abre APENAS o vocabul√°rio para leitura (sem criar arquivo de log)
    with open(vocab_path, "r", encoding="utf-8") as f_entrada:
        for i, line in enumerate(f_entrada):
            palavra = line.strip()
            
            # Verifica se a palavra serve para o jogo
            if palavra_eh_valida(palavra):
                palavras_validas.append(palavra)
                indices_validos.append(i) # Guarda a "coordenada" da linha

    print(f"‚úÖ Filtro conclu√≠do! {len(palavras_validas)} palavras aprovadas.")

    # Carrega a matriz gigante de n√∫meros
    dados_completos = load_file(emb_path)
    matriz_inteira = dados_completos["embeddings"]
    
    # Pega APENAS as linhas que correspondem √†s palavras aprovadas
    vetores_filtrados = matriz_inteira[indices_validos]

    # Cria o objeto final limpo
    word2vec = KeyedVectors(vector_size=300)
    word2vec.add_vectors(palavras_validas, vetores_filtrados)

    print("‚úÖ Modelo Word2Vec carregado e filtrado com sucesso!")

except Exception as e:
    print(f"‚ùå Erro cr√≠tico: {e}")
    word2vec = None








if word2vec:
    palavra_teste = "computador" # Troque pela palavra que quiser testar

    print(f"\nüîç Buscando similares para: '{palavra_teste}'")

    try:
        # Busca as 10 palavras mais pr√≥ximas
        resultado = word2vec.most_similar(palavra_teste, topn=10)
        
        for palavra, score in resultado:
            print(f" -> {palavra} (Similaridade: {score:.2f})")
            
    except KeyError:
        print(f"‚ö†Ô∏è A palavra '{palavra_teste}' n√£o existe no modelo filtrado.")